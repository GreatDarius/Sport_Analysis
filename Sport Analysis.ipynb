{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset\n",
    "baseball = pd.read_csv(\"baseball.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attendance_binary</th>\n",
       "      <th>previous_attendance</th>\n",
       "      <th>previous_away_team_errors</th>\n",
       "      <th>previous_away_team_hits</th>\n",
       "      <th>previous_away_team_runs</th>\n",
       "      <th>game_type</th>\n",
       "      <th>previous_game_type</th>\n",
       "      <th>previous_home_team_errors</th>\n",
       "      <th>previous_home_team_hits</th>\n",
       "      <th>previous_home_team_runs</th>\n",
       "      <th>game_day</th>\n",
       "      <th>previous_game_day</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>sky</th>\n",
       "      <th>previous_game_duration</th>\n",
       "      <th>previous_homewin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>43683</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Night Game</td>\n",
       "      <td>Day Game</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>55</td>\n",
       "      <td>24</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>45785</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Night Game</td>\n",
       "      <td>Day Game</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>48282</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Night Game</td>\n",
       "      <td>Day Game</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>3.383333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21830</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>Day Game</td>\n",
       "      <td>Night Game</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>In Dome</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>49289</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Night Game</td>\n",
       "      <td>Day Game</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>2.633333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attendance_binary  previous_attendance  previous_away_team_errors  \\\n",
       "0                  0                43683                          2   \n",
       "1                  0                45785                          0   \n",
       "2                  0                48282                          0   \n",
       "3                  0                21830                          0   \n",
       "4                  0                49289                          2   \n",
       "\n",
       "   previous_away_team_hits  previous_away_team_runs   game_type  \\\n",
       "0                        6                        2  Night Game   \n",
       "1                        7                        2  Night Game   \n",
       "2                        8                        4  Night Game   \n",
       "3                        9                        6    Day Game   \n",
       "4                        4                        2  Night Game   \n",
       "\n",
       "  previous_game_type  previous_home_team_errors  previous_home_team_hits  \\\n",
       "0           Day Game                          0                        6   \n",
       "1           Day Game                          0                       10   \n",
       "2           Day Game                          2                        4   \n",
       "3         Night Game                          0                       15   \n",
       "4           Day Game                          1                        1   \n",
       "\n",
       "   previous_home_team_runs   game_day previous_game_day  temperature  \\\n",
       "0                        6  Wednesday            Monday           55   \n",
       "1                        3  Wednesday            Monday           48   \n",
       "2                        3  Wednesday            Monday           65   \n",
       "3                       11  Wednesday           Tuesday           77   \n",
       "4                        3    Tuesday            Monday           81   \n",
       "\n",
       "   wind_speed       sky  previous_game_duration  previous_homewin  \n",
       "0          24  Overcast                2.933333                 1  \n",
       "1           7   Unknown                2.800000                 1  \n",
       "2          10    Cloudy                3.383333                 0  \n",
       "3           0   In Dome                3.233333                 1  \n",
       "4          12    Cloudy                2.633333                 1  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(baseball, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping usless columns, since this column is not useful for binary classification\n",
    "train = train_set\n",
    "test = test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking our dataset for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attendance_binary            0\n",
       "previous_attendance          0\n",
       "previous_away_team_errors    0\n",
       "previous_away_team_hits      0\n",
       "previous_away_team_runs      0\n",
       "game_type                    0\n",
       "previous_game_type           0\n",
       "previous_home_team_errors    0\n",
       "previous_home_team_hits      0\n",
       "previous_home_team_runs      0\n",
       "game_day                     0\n",
       "previous_game_day            0\n",
       "temperature                  0\n",
       "wind_speed                   0\n",
       "sky                          0\n",
       "previous_game_duration       0\n",
       "previous_homewin             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attendance_binary            0\n",
       "previous_attendance          0\n",
       "previous_away_team_errors    0\n",
       "previous_away_team_hits      0\n",
       "previous_away_team_runs      0\n",
       "game_type                    0\n",
       "previous_game_type           0\n",
       "previous_home_team_errors    0\n",
       "previous_home_team_hits      0\n",
       "previous_home_team_runs      0\n",
       "game_day                     0\n",
       "previous_game_day            0\n",
       "temperature                  0\n",
       "wind_speed                   0\n",
       "sky                          0\n",
       "previous_game_duration       0\n",
       "previous_homewin             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we have no missing values we do not need to performe any cleaning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed libraries\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating target variable to prevent any transformation on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train[['attendance_binary']]\n",
    "test_y = test[['attendance_binary']]\n",
    "\n",
    "train_inputs = train.drop(['attendance_binary'], axis=1)\n",
    "test_inputs = test.drop(['attendance_binary'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying and Seperating Numeric and Categorical and Binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "previous_attendance            int64\n",
       "previous_away_team_errors      int64\n",
       "previous_away_team_hits        int64\n",
       "previous_away_team_runs        int64\n",
       "game_type                     object\n",
       "previous_game_type            object\n",
       "previous_home_team_errors      int64\n",
       "previous_home_team_hits        int64\n",
       "previous_home_team_runs        int64\n",
       "game_day                      object\n",
       "previous_game_day             object\n",
       "temperature                    int64\n",
       "wind_speed                     int64\n",
       "sky                           object\n",
       "previous_game_duration       float64\n",
       "previous_homewin               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numerical columns\n",
    "numeric_columns = train_inputs.select_dtypes(include=[np.number]).columns.to_list()\n",
    "\n",
    "# Identify the categorical columns\n",
    "categorical_columns = train_inputs.select_dtypes('object').columns.to_list()\n",
    "\n",
    "# Identify the binary columns so we can pass them through without transforming\n",
    "binary_columns = ['previous_homewin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['previous_attendance',\n",
       " 'previous_away_team_errors',\n",
       " 'previous_away_team_hits',\n",
       " 'previous_away_team_runs',\n",
       " 'previous_home_team_errors',\n",
       " 'previous_home_team_hits',\n",
       " 'previous_home_team_runs',\n",
       " 'temperature',\n",
       " 'wind_speed',\n",
       " 'previous_game_duration',\n",
       " 'previous_homewin']"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['game_type', 'previous_game_type', 'game_day', 'previous_game_day', 'sky']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['previous_homewin']"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing binary columns from numeric columns\n",
    "for col in binary_columns:\n",
    "    numeric_columns.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['previous_attendance',\n",
       " 'previous_away_team_errors',\n",
       " 'previous_away_team_hits',\n",
       " 'previous_away_team_runs',\n",
       " 'previous_home_team_errors',\n",
       " 'previous_home_team_hits',\n",
       " 'previous_home_team_runs',\n",
       " 'temperature',\n",
       " 'wind_speed',\n",
       " 'previous_game_duration']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Piplining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)],\n",
    "        remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit_Transform() for Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.12371621,  0.57666325, -0.20719118, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.05787587, -0.72716391, -0.78017264, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.38394295,  0.57666325, -1.35315411, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [-0.52534761,  0.57666325, -0.78017264, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.94392488, -0.72716391,  0.65228102, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.98407336,  1.88049041, -0.49368191, ...,  1.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit and transform the train data\n",
    "train_x = preprocessor.fit_transform(train_inputs)\n",
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1698, 37)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform() For Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0814842 ,  1.88049041, -1.06666338, ...,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.17001331, -0.72716391, -1.63964484, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.29905768, -0.72716391, -0.20719118, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.49582715, -0.72716391,  1.22526249, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.26445059, -0.72716391, -0.20719118, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-1.71775245, -0.72716391, -1.63964484, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data\n",
    "test_x = preprocessor.transform(test_inputs)\n",
    "\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(729, 37)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Columns in both Train and Test are equal which means we can start building our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we need to find Base Line Accuracy so we can compare the accuracy of our model against baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attendance_binary\n",
       "1                    873\n",
       "0                    825\n",
       "dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find majority class\n",
    "train_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The majority is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attendance_binary\n",
       "1                    0.514134\n",
       "0                    0.485866\n",
       "dtype: float64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find percentage\n",
    "train_y.value_counts()/len(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### According to our  result the base line is 52%. So any model that does not perform better than 52% is not a valueable model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: (3 points in total)\n",
    "\n",
    "Build three different SVM models (by changing the kernels, regularization, etc.). Generate their training and test values. Each model is worth 1 point. \n",
    "\n",
    "(Add cells as needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model 1: linearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing SVM from sklearn\n",
    "from sklearn.svm import LinearSVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moein.f\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Moein.f\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating our model\n",
    "svm_linear = LinearSVC(C=1)\n",
    "\n",
    "svm_linear.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing accuracy score from sklearn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8439340400471143"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the train values\n",
    "train_y_pred = svm_linear.predict(train_x)\n",
    "\n",
    "#Train accuracy\n",
    "accuracy_score(train_y, train_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8148148148148148"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the test values\n",
    "test_y_pred = svm_linear.predict(test_x)\n",
    "\n",
    "#Test accuracy\n",
    "accuracy_score(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[273,  70],\n",
       "       [ 66, 320]], dtype=int64)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use Confusion matrix to check the accuracy of our model further\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#We usually create the confusion matrix on test set\n",
    "confusion_matrix(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80       343\n",
      "           1       0.82      0.83      0.82       386\n",
      "\n",
      "    accuracy                           0.81       729\n",
      "   macro avg       0.81      0.81      0.81       729\n",
      "weighted avg       0.81      0.81      0.81       729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#We usually create the classification report on test set\n",
    "print(classification_report(test_y, test_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our model performs better than baseline and there is no overfitting. however there might be underfitting, we can check that by creating more models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model 2: Linear SVC with Polynomial Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create second degree terms\n",
    "poly_features = PolynomialFeatures(degree=1, include_bias=False)\n",
    "\n",
    "train_x_poly = poly_features.fit_transform(train_x)\n",
    "\n",
    "#Don't forget to transform the test set\n",
    "test_x_poly = poly_features.transform(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moein.f\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Moein.f\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_svm = LinearSVC(C=1)\n",
    "\n",
    "pol_svm.fit(train_x_poly, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8439340400471143"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the train values\n",
    "train_y_poly_pred = pol_svm.predict(train_x_poly)\n",
    "\n",
    "#Train accuracy\n",
    "accuracy_score(train_y, train_y_poly_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8148148148148148"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the test values\n",
    "test_y_poly_pred = pol_svm.predict(test_x_poly)\n",
    "\n",
    "#Test accuracy\n",
    "accuracy_score(test_y, test_y_poly_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eventhough our polynomial model performs better (99%) with degree of 3 on train set but we will have overfitting since our test set accuracy will be 76%. So by reducing degree to 1 and c value to 1, we have a better accuracy on test set (81%). By doing so we will deal with overfitting issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model 3: SVC(kernel='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moein.f\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    " \n",
    "lin_svm2 = SVC(kernel=\"linear\")\n",
    "\n",
    "lin_svm2.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8445229681978799"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the train values\n",
    "train_y_pred = lin_svm2.predict(train_x)\n",
    "\n",
    "#Train accuracy\n",
    "accuracy_score(train_y, train_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8175582990397805"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the test values\n",
    "test_y_pred = lin_svm2.predict(test_x)\n",
    "\n",
    "#Test accuracy\n",
    "accuracy_score(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our model does not perform better that linear one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model 4: SVC(kernel='rbf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moein.f\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=10)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_svm = SVC(kernel=\"rbf\", C=10, gamma='scale')\n",
    "\n",
    "rbf_svm.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9705535924617197"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the train values\n",
    "train_y_pred = rbf_svm.predict(train_x)\n",
    "\n",
    "#Train accuracy\n",
    "accuracy_score(train_y, train_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7997256515775034"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the test values\n",
    "test_y_pred = rbf_svm.predict(test_x)\n",
    "\n",
    "#Test accuracy\n",
    "accuracy_score(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In rbf model with C value of 10 we face overfitting issue since our train set accuracy is 97% but the test accuracy is only 79%. We can reduce C to 1 which will give us 88% accuracy on train and 82% accuracy on test set. the amount of overfitting drastically reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: (3 points in total)\n",
    "\n",
    "Build two different SGD models (by changing the penalty, etc. or adding polynomial terms) and one LogisticRregression model. Generate their training and test values. Each model is worth 1 point.\n",
    "\n",
    "(Add cells as needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Model 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moein.f\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, penalty=None, random_state=1, tol=0.0001)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier \n",
    "\n",
    "# tol = stopping criterion\n",
    "# eta0 = learning rate\n",
    "# penalty = regularization term\n",
    "# max_iter = number of passes over training data (i.e., epochs)\n",
    "\n",
    "sgd_logreg = SGDClassifier(random_state=1 ,max_iter=1000, penalty=None, eta0=0.0001, tol=0.0001) \n",
    "\n",
    "sgd_logreg.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8286219081272085"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the train values\n",
    "train_y_pred = sgd_logreg.predict(train_x)\n",
    "\n",
    "#Train accuracy\n",
    "accuracy_score(train_y, train_y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803840877914952"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the test values\n",
    "test_y_pred = sgd_logreg.predict(test_x)\n",
    "\n",
    "#Test accuracy\n",
    "accuracy_score(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our SGD model accuracy is 81% for train and 79% for test which is not better than our previous models so eventhough this model is performing better than baseline and there is no overfitting but we have underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Model 2: penalty='elasticnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moein.f\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.01, penalty='elasticnet', tol=1e-05)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier \n",
    "\n",
    "# tol = stopping criterion\n",
    "# eta0 = learning rate\n",
    "# penalty = regularization term\n",
    "# max_iter = number of passes over training data (i.e., epochs)\n",
    "\n",
    "sgd_logreg2 = SGDClassifier(max_iter=1000, penalty='elasticnet', eta0=0.01, tol=0.00001) \n",
    "\n",
    "sgd_logreg2.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8244994110718492"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the train values\n",
    "train_y_pred = sgd_logreg2.predict(train_x)\n",
    "\n",
    "#Train accuracy\n",
    "accuracy_score(train_y, train_y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7846364883401921"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the test values\n",
    "test_y_pred = sgd_logreg2.predict(test_x)\n",
    "\n",
    "#Test accuracy\n",
    "accuracy_score(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this models did not perform better than previus ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moein.f\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Moein.f\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='none')"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(penalty='none')\n",
    "\n",
    "log_reg.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8468786808009423"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the train values\n",
    "train_y_pred = log_reg.predict(train_x)\n",
    "\n",
    "#Train accuracy\n",
    "accuracy_score(train_y, train_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8161865569272977"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the test values\n",
    "test_y_pred = log_reg.predict(test_x)\n",
    "\n",
    "#Test accuracy\n",
    "accuracy_score(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eventhough there is a slight overfitting problem but the logistic regressionmodel did not performe better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion (3 points in total)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List the train and test values of each model you built (1 point)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BaseLine: 52%\n",
    "SVM Model 1(linearSVC): 81%\n",
    "SVM Model 2(Linear SVC with Polynomial Terms): 81%\n",
    "SVM Model 3(SVC(kernel='linear')): 81%\n",
    "SVM Model 4(SVC(kernel='rbf')): 82%\n",
    "SGD Model 1: 79%\n",
    "SGD Model 2(penalty='elasticnet'): 78%\n",
    "LogisticRegression Model: 81%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model performs the best and why? (0.5 points) How does it compare to baseline? (0.5 points)\n",
    "\n",
    "Hint: The best model is the one that has the highest TEST score (regardless of any of the training values). If you select your model based on TRAIN values, you will lose points."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SVM Model _SVC with Kernel='rbf' performed slightly better than others but not that much. if we use C value 10 there will be a huge overfitting problem, but by using C value 1 we do not have overfitting problem. Since the base line is 51% all of our models out performed the base line by around 40 percent more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is there any evidence of overfitting in the best model, why or why not? If there is, what did you do about it? (0.5 points)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In the initial values of the best model there was an overfitting problem 97% train accuracy versus 79% test accuracy. in fact the best model was one of the worst models. by changing the value of c from 10 to 1 we reduced overfitting and we achieved better resault."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is there any evidence of overfitting in the other models (besides the best model), why or why not? If there is, what did you do about it? (0.5 points)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
